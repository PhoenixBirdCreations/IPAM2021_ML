{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.special import logit, expit\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(MultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ZeroMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(\n",
    "                #lengthscale_prior = gpytorch.priors.NormalPrior(10,100),\n",
    "                lengthscale_constraint = gpytorch.constraints.Interval(1e1,1e4),\n",
    "                alpha_constraint = gpytorch.constraints.Interval(1e-2,1e2),\n",
    "                #ard_num_dims = 2,\n",
    "                #outputscale_prior = gpytorch.priors.NormalPrior(10,100),\n",
    "                #outputscale_constraint = gpytorch.constraints.Interval(1e2,1e5),\n",
    "            ))\n",
    "        # length_scale_bounds = [1e-10,1e10],alpha_bounds = [1e-10,1e10]\n",
    "        #self.covar_module.initialize_from_data(train_x, train_y)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global num_classifications\n",
    "num_classifications = 50\n",
    "X = np.linspace(0,num_classifications,num_classifications+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_fit(x,a,b):\n",
    "    return ((1+b*x)*np.exp(a*x)-1)/((1+b)*np.exp(a)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 6\n",
    "noise_level_NS = 0.0001/num_classifications\n",
    "noise_level_REM = 0.0001/num_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes = pd.read_csv('BayesFactors.csv',delimiter=',')\n",
    "Bayes_factors = Bayes['BayesFactor'] / np.sum(Bayes['BayesFactor'])\n",
    "\n",
    "P_NS_given_X1pX2_num = pd.DataFrame({'X1+X2': X/num_classifications})#.astype({'X1+X2': np.int32})  \n",
    "P_REM_given_X2_num = pd.DataFrame({'X2': X/num_classifications})#.astype({'X2': np.int32})\n",
    "                                                        \n",
    "P_NS_given_X1pX2_table = pd.DataFrame({'X1+X2': X/num_classifications})#.astype({'X1+X2': np.int32})\n",
    "P_REM_given_X2_table =pd.DataFrame({'X2': X/num_classifications})#.astype({'X2': np.int32})\n",
    "\n",
    "P_NS_given_X1pX2_table_an = pd.DataFrame({'X1+X2': X/num_classifications})#.astype({'X1+X2': np.int32})\n",
    "P_REM_given_X2_table_an = pd.DataFrame({'X2': X/num_classifications})#.astype({'X2': np.int32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:130: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n",
      "/home/cavaglia/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for EOS_tag in Bayes['EOS']:\n",
    "    test_file = 'matrix_events_'+algorithm+'_EOS-' + EOS_tag + '.csv'\n",
    "\n",
    "    classification_results = pd.read_csv(test_file,delimiter=',')#.dropna(axis=1) #, nrows=20)\n",
    "\n",
    "    probability_dataframe = pd.DataFrame()\n",
    "    file_tag = test_file.split('.')[0]\n",
    "    log_file =  'log-' + file_tag + '.txt'\n",
    "\n",
    "    P_NS_tag = 'P_NS('+EOS_tag+')'\n",
    "\n",
    "    probability_dataframe['LABEL'] = classification_results['HasNS_true'] + \\\n",
    "                                          classification_results['HasREM_true']\n",
    "    probability_dataframe['X0'] = np.round(classification_results['f_0'] * num_classifications,0)\n",
    "    probability_dataframe['X1'] = np.round(classification_results['f_1'] * num_classifications,0)\n",
    "    probability_dataframe['X2'] = np.round(classification_results['f_2'] * num_classifications,0)\n",
    "    probability_dataframe['X1+X2'] = np.round((classification_results['f_1'] + \\\n",
    "                                           classification_results['f_2']) * num_classifications,0)\n",
    "    probability_dataframe = probability_dataframe.fillna(0)\n",
    "\n",
    "    N_events = len(probability_dataframe)\n",
    "\n",
    "    NS = probability_dataframe[probability_dataframe['LABEL']>0]\n",
    "    N_NS = len(NS)\n",
    "    P_NS = N_NS / N_events\n",
    "    N_X1pX2 = np.array([len(probability_dataframe[probability_dataframe['X1+X2']==el]) for el in X])\n",
    "    N_X1pX2_given_NS = np.array([len(NS[NS['X1+X2']==el]) for el in X])\n",
    "    P_X1pX2 = N_X1pX2 / N_events\n",
    "    P_X1pX2_given_NS = N_X1pX2_given_NS / N_NS\n",
    "    P_NS_given_X1pX2 = np.divide(P_X1pX2_given_NS,P_X1pX2) * P_NS\n",
    "\n",
    "    P_NS_given_X1pX2_num[P_NS_tag] = P_NS_given_X1pX2\n",
    "    P_NS_given_X1pX2_num = P_NS_given_X1pX2_num.fillna(method='ffill')\n",
    "    P_NS_given_X1pX2_num = P_NS_given_X1pX2_num.round({P_NS_tag:precision})\n",
    "        \n",
    "    P_NS_given_X1pX2_fit = P_NS_given_X1pX2_num \n",
    "    \n",
    "    P_NS_given_X1pX2_fit.loc[P_NS_given_X1pX2_fit[P_NS_tag] == 0.0,P_NS_tag] =  \\\n",
    "        P_NS_given_X1pX2_fit[P_NS_tag].apply(lambda x: noise_level_NS*np.random.rand())\n",
    "    P_NS_given_X1pX2_fit.loc[P_NS_given_X1pX2_fit[P_NS_tag] == 1.0,P_NS_tag] = \\\n",
    "        P_NS_given_X1pX2_fit[P_NS_tag].apply(lambda x: 1.0-noise_level_NS*np.random.rand())\n",
    "    \n",
    "    P_NS_given_X1pX2_logit = logit(P_NS_given_X1pX2_fit[P_NS_tag].values)\n",
    "       \n",
    "    P_NS_given_X1pX2_logit = savgol_filter(P_NS_given_X1pX2_logit,2,1) \n",
    "\n",
    "    P_NS_given_X1pX2_logit_array = P_NS_given_X1pX2_logit.reshape(-1,1)\n",
    "    P_NS_given_X1pX2_scaler = preprocessing.StandardScaler().fit(P_NS_given_X1pX2_logit_array)\n",
    "    P_NS_given_X1pX2_scaled = P_NS_given_X1pX2_scaler.transform(P_NS_given_X1pX2_logit_array).flatten()\n",
    "\n",
    "    P_NS_given_X1pX2_train_x = torch.from_numpy(np.linspace(0,num_classifications,len(P_NS_given_X1pX2_scaled))).to(torch.float64)\n",
    "    P_NS_given_X1pX2_train_y = torch.from_numpy(P_NS_given_X1pX2_scaled).to(torch.float64)\n",
    "    P_NS_given_X1pX2_test_x = torch.from_numpy(X).to(torch.float64)\n",
    "\n",
    "    likelihood_P_NS_given_X1pX2 = gpytorch.likelihoods.GaussianLikelihood(num_tasks=2)\n",
    "    model_P_NS_given_X1pX2 = MultitaskGPModel(P_NS_given_X1pX2_train_x, P_NS_given_X1pX2_train_y, \\\n",
    "                                      likelihood_P_NS_given_X1pX2)\n",
    "    model_P_NS_given_X1pX2.train()\n",
    "    likelihood_P_NS_given_X1pX2.train()\n",
    "\n",
    "    optimizer_P_NS_given_X1pX2 = torch.optim.Adam([\n",
    "    {'params': model_P_NS_given_X1pX2.parameters()},  # Includes GaussianLikelihood parameters\n",
    "    ], lr=1)\n",
    "\n",
    "    mll_P_NS_given_X1pX2 = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood_P_NS_given_X1pX2, \\\n",
    "                                                            model_P_NS_given_X1pX2)\n",
    "\n",
    "    n_iter_P_NS_given_X1pX2 = 100\n",
    "    for i in range(n_iter_P_NS_given_X1pX2):\n",
    "        optimizer_P_NS_given_X1pX2.zero_grad()\n",
    "        output_P_NS_given_X1pX2 = model_P_NS_given_X1pX2(P_NS_given_X1pX2_train_x)\n",
    "        loss_P_NS_given_X1pX2 = -mll_P_NS_given_X1pX2(output_P_NS_given_X1pX2, P_NS_given_X1pX2_train_y).sum()\n",
    "        loss_P_NS_given_X1pX2.backward()\n",
    "        optimizer_P_NS_given_X1pX2.step()\n",
    "\n",
    "    model_P_NS_given_X1pX2.eval()\n",
    "    likelihood_P_NS_given_X1pX2.eval()  \n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        P_NS_given_X1pX2_predictions = likelihood_P_NS_given_X1pX2(model_P_NS_given_X1pX2(P_NS_given_X1pX2_test_x))\n",
    "        P_NS_given_X1pX2_mean = P_NS_given_X1pX2_predictions.mean\n",
    "        lower_P_NS_given_X1pX2, upper_P_NS_given_X1pX2 = P_NS_given_X1pX2_predictions.confidence_region()\n",
    "\n",
    "    P_NS_given_X1pX2_fitted = P_NS_given_X1pX2_scaler.inverse_transform(P_NS_given_X1pX2_mean.numpy().reshape(-1,1))\n",
    "    P_NS_given_X1pX2_expit = expit(P_NS_given_X1pX2_fitted)\n",
    "    P_NS_given_X1pX2_expit = P_NS_given_X1pX2_expit.reshape(num_classifications+1,-1)\n",
    "    P_NS_given_X1pX2_table[P_NS_tag] = P_NS_given_X1pX2_expit   \n",
    "\n",
    "    popt_NS,pcov_NS = curve_fit(analytical_fit,P_NS_given_X1pX2_num['X1+X2'],\n",
    "                                savgol_filter(P_NS_given_X1pX2_num[P_NS_tag],2,1))\n",
    "    analytical_fit_NS = analytical_fit(P_NS_given_X1pX2_num['X1+X2'],*popt_NS)\n",
    "\n",
    "    P_NS_given_X1pX2_table_an[P_NS_tag] = analytical_fit_NS\n",
    "\n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.scatter(P_NS_given_X1pX2_num['X1+X2'],P_NS_given_X1pX2_num[P_NS_tag],cmap='viridis')\n",
    "    ax.scatter(P_NS_given_X1pX2_table['X1+X2'],P_NS_given_X1pX2_table[P_NS_tag],cmap='viridis')\n",
    "    ax.scatter(P_NS_given_X1pX2_table_an['X1+X2'],analytical_fit_NS,cmap='viridis')\n",
    "\n",
    "    plt.xlabel('X1+X2')\n",
    "    plt.ylabel('P_NS')\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(which='both')\n",
    "    plt.savefig(algorithm+'_P_NS_given_X1pX2-'+EOS_tag+'-num.png',dpi=300,facecolor='w')\n",
    "    plt.close()\n",
    "\n",
    "    probability_dataframe_NS = probability_dataframe[probability_dataframe.LABEL != 0]\n",
    "    P_REM_tag = 'P_REM('+EOS_tag+')'\n",
    "\n",
    "    REM = probability_dataframe_NS[probability_dataframe_NS['LABEL']==2]\n",
    "\n",
    "    N_events_NS = len(probability_dataframe_NS)\n",
    "    N_REM = len(REM)\n",
    "    P_REM = N_REM / N_events_NS\n",
    "    N_X2 = np.array([len(probability_dataframe_NS[probability_dataframe_NS['X2']==el]) for el in X])\n",
    "    N_X2_given_REM = np.array([len(REM[REM['X2']==el]) for el in X])\n",
    "    P_X2 = N_X2 / N_events_NS\n",
    "    P_X2_given_REM = N_X2_given_REM / N_REM\n",
    "    P_REM_given_X2 = np.divide(P_X2_given_REM,P_X2) * P_REM\n",
    "\n",
    "    P_REM_given_X2 = P_NS_given_X1pX2 * P_REM_given_X2\n",
    "\n",
    "    P_REM_given_X2_num[P_REM_tag] =  P_REM_given_X2\n",
    "    \n",
    "    \n",
    "    P_REM_given_X2_num = P_REM_given_X2_num.fillna(method='ffill')\n",
    "    P_REM_given_X2_num = P_REM_given_X2_num.round({P_REM_tag:precision})\n",
    "\n",
    "    P_REM_given_X2_fit = P_REM_given_X2_num \n",
    "\n",
    "    P_REM_given_X2_fit.loc[P_REM_given_X2_fit[P_REM_tag] == 0.0,P_REM_tag] =  \\\n",
    "        P_REM_given_X2_fit[P_REM_tag].apply(lambda x: noise_level_REM*np.random.rand())\n",
    "    P_REM_given_X2_fit.loc[P_REM_given_X2_fit[P_REM_tag] == 1.0,P_REM_tag] = \\\n",
    "        P_REM_given_X2_fit[P_REM_tag].apply(lambda x: 1.0-noise_level_REM*np.random.rand())\n",
    "\n",
    "    P_REM_given_X2_logit = logit(P_REM_given_X2_fit[P_REM_tag].values)\n",
    "\n",
    "    P_REM_given_X2_logit = savgol_filter(P_REM_given_X2_logit,2,1) \n",
    "    \n",
    "    P_REM_given_X2_logit_array = P_REM_given_X2_logit.reshape(-1,1)\n",
    "    P_REM_given_X2_scaler = preprocessing.StandardScaler().fit(P_REM_given_X2_logit_array)\n",
    "    P_REM_given_X2_scaled = P_REM_given_X2_scaler.transform(P_REM_given_X2_logit_array).flatten()\n",
    "\n",
    "    P_REM_given_X2_train_x = torch.from_numpy(np.linspace(0,num_classifications,len(P_REM_given_X2_scaled))).to(torch.float64)\n",
    "    P_REM_given_X2_train_y = torch.from_numpy(P_REM_given_X2_scaled).to(torch.float64)\n",
    "    P_REM_given_X2_test_x = torch.from_numpy(X).to(torch.float64)\n",
    "\n",
    "    likelihood_P_REM_given_X2 = gpytorch.likelihoods.GaussianLikelihood(num_tasks=2)\n",
    "    model_P_REM_given_X2 = MultitaskGPModel(P_REM_given_X2_train_x, P_REM_given_X2_train_y, \\\n",
    "                                    likelihood_P_REM_given_X2)\n",
    "    model_P_REM_given_X2.train()\n",
    "    likelihood_P_REM_given_X2.train()\n",
    "\n",
    "    optimizer_P_REM_given_X2 = torch.optim.Adam([\n",
    "        {'params': model_P_REM_given_X2.parameters()},  # Includes GaussianLikelihood parameters\n",
    "        ], lr=1)\n",
    "\n",
    "    mll_P_REM_given_X2 = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood_P_REM_given_X2, \\\n",
    "                                                        model_P_REM_given_X2)\n",
    "\n",
    "    n_iter_P_REM_given_X2 = 100\n",
    "    for i in range(n_iter_P_REM_given_X2):\n",
    "        optimizer_P_REM_given_X2.zero_grad()\n",
    "        output_P_REM_given_X2 = model_P_REM_given_X2(P_REM_given_X2_train_x)\n",
    "        loss_P_REM_given_X2 = -mll_P_REM_given_X2(output_P_REM_given_X2, P_REM_given_X2_train_y).sum()\n",
    "        loss_P_REM_given_X2.backward()\n",
    "        optimizer_P_REM_given_X2.step()\n",
    "\n",
    "    model_P_REM_given_X2.eval()\n",
    "    likelihood_P_REM_given_X2.eval()  \n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        P_REM_given_X2_predictions = likelihood_P_REM_given_X2(model_P_REM_given_X2(P_REM_given_X2_test_x))\n",
    "        P_REM_given_X2_mean = P_REM_given_X2_predictions.mean\n",
    "        lower_P_REM_given_X2, upper_P_REM_given_X2 = P_REM_given_X2_predictions.confidence_region()\n",
    "\n",
    "    P_REM_given_X2_fitted = P_REM_given_X2_scaler.inverse_transform(P_REM_given_X2_mean.numpy().reshape(-1,1))\n",
    "    P_REM_given_X2_expit = expit(P_REM_given_X2_fitted)\n",
    "    P_REM_given_X2_expit = P_REM_given_X2_expit.reshape(num_classifications+1,-1)\n",
    "    P_REM_given_X2_table[P_REM_tag] = P_REM_given_X2_expit   \n",
    "    \n",
    "    popt_REM,pcov_REM = curve_fit(analytical_fit,P_REM_given_X2_num['X2'],\n",
    "                                  savgol_filter(P_REM_given_X2_num[P_REM_tag],2,1))\n",
    "    analytical_fit_REM = analytical_fit(P_REM_given_X2_num['X2'],*popt_REM)\n",
    "    P_REM_given_X2_table_an[P_REM_tag] = analytical_fit_REM    \n",
    "        \n",
    "    fig = plt.figure(figsize=(12,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.scatter(P_REM_given_X2_num['X2'],P_REM_given_X2_num[P_REM_tag],cmap='viridis')\n",
    "    ax.scatter(P_REM_given_X2_table['X2'],P_REM_given_X2_table[P_REM_tag],cmap='viridis')\n",
    "    ax.scatter(P_REM_given_X2_table_an['X2'],analytical_fit_REM,cmap='viridis')\n",
    "\n",
    "    plt.xlabel('X2')\n",
    "    plt.ylabel('P_REM')\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(which='both')\n",
    "    plt.savefig(algorithm+'_P_REM_given_X2-'+EOS_tag+'-num.png',dpi=300,facecolor='w')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "P_NS_given_X1pX2_num.to_csv(algorithm+'_P_NS_given_X1pX2-num.csv',index=False,float_format='%.'+str(precision)+'f')\n",
    "P_NS_given_X1pX2_table.to_csv(algorithm+'_P_NS_given_X1pX2-fit.csv',index=False,float_format='%.'+str(precision)+'f')\n",
    "P_NS_given_X1pX2_table_an.to_csv(algorithm+'_P_NS_given_X1pX2-fit_an.csv',index=False,float_format='%.'+str(precision)+'f')    \n",
    "    \n",
    "P_REM_given_X2_num.to_csv(algorithm+'_P_REM_given_X2-num.csv',index=False,float_format='%.'+str(precision)+'f')\n",
    "P_REM_given_X2_table.to_csv(algorithm+'_P_REM_given_X2-fit.csv',index=False,float_format='%.'+str(precision)+'f')\n",
    "P_REM_given_X2_table_an.to_csv(algorithm+'_P_REM_given_X2-fit_an.csv',index=False,float_format='%.'+str(precision)+'f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_NS_given_X1pX2_num_Bayes = P_NS_given_X1pX2_num.iloc[:,1:]\n",
    "P_NS_given_X1pX2_num_Bayes.columns = range(len(Bayes_factors))\n",
    "P_NS_given_X1pX2_num_Bayes = P_NS_given_X1pX2_num_Bayes.mul(Bayes_factors)\n",
    "P_NS_given_X1pX2_num_Bayes.rename(columns='P_NS('+Bayes['EOS']+')',inplace=True)\n",
    "P_NS_given_X1pX2_num_Bayes.insert(0,'X1+X2',P_NS_given_X1pX2_num['X1+X2'])\n",
    "\n",
    "P_NS_given_X1pX2_num_Bayes.to_csv(algorithm+'_P_NS_given_X1pX2-BF-num.csv',index=False,float_format='%.'+str(precision)+'f')\n",
    "\n",
    "P_NS_given_X1pX2_table_Bayes = P_NS_given_X1pX2_table.iloc[:,1:]\n",
    "P_NS_given_X1pX2_table_Bayes.columns = range(len(Bayes_factors))\n",
    "P_NS_given_X1pX2_table_Bayes = P_NS_given_X1pX2_table_Bayes.mul(Bayes_factors)\n",
    "P_NS_given_X1pX2_table_Bayes.rename(columns='P_NS('+Bayes['EOS']+')',inplace=True)\n",
    "P_NS_given_X1pX2_table_Bayes.insert(0,'X1+X2',P_NS_given_X1pX2_table['X1+X2'])\n",
    "\n",
    "P_NS_given_X1pX2_table_Bayes.to_csv(algorithm+'_P_NS_given_X1pX2-BF-fit.csv',index=False,float_format='%.'+str(precision)+'f')   \n",
    "\n",
    "P_NS_given_X1pX2_table_an_Bayes = P_NS_given_X1pX2_table_an.iloc[:,1:]\n",
    "P_NS_given_X1pX2_table_an_Bayes.columns = range(len(Bayes_factors))\n",
    "P_NS_given_X1pX2_table_an_Bayes = P_NS_given_X1pX2_table_an_Bayes.mul(Bayes_factors)\n",
    "P_NS_given_X1pX2_table_an_Bayes.rename(columns='P_NS('+Bayes['EOS']+')',inplace=True)\n",
    "P_NS_given_X1pX2_table_an_Bayes.insert(0,'X1+X2',P_NS_given_X1pX2_table_an['X1+X2'])\n",
    "\n",
    "P_NS_given_X1pX2_table_an_Bayes.to_csv(algorithm+'_P_NS_given_X1pX2-BF-fit_an.csv',index=False,float_format='%.'+str(precision)+'f')\n",
    "\n",
    "P_REM_given_X2_num_Bayes = P_REM_given_X2_num.iloc[:,1:]\n",
    "P_REM_given_X2_num_Bayes.columns = range(len(Bayes_factors))\n",
    "P_REM_given_X2_num_Bayes = P_REM_given_X2_num_Bayes.mul(Bayes_factors)\n",
    "P_REM_given_X2_num_Bayes.rename(columns='P_REM('+Bayes['EOS']+')',inplace=True)\n",
    "P_REM_given_X2_num_Bayes.insert(0,'X2',P_REM_given_X2_num['X2'])\n",
    "\n",
    "P_REM_given_X2_num_Bayes.to_csv(algorithm+'_P_REM_given_X2-BF-num.csv',index=False,float_format='%.'+str(precision)+'f')\n",
    "\n",
    "P_REM_given_X2_table_Bayes = P_REM_given_X2_table.iloc[:,1:]\n",
    "P_REM_given_X2_table_Bayes.columns = range(len(Bayes_factors))\n",
    "P_REM_given_X2_table_Bayes = P_REM_given_X2_table_Bayes.mul(Bayes_factors)\n",
    "P_REM_given_X2_table_Bayes.rename(columns='P_REM('+Bayes['EOS']+')',inplace=True)\n",
    "P_REM_given_X2_table_Bayes.insert(0,'X2',P_REM_given_X2_table['X2'])\n",
    "\n",
    "P_REM_given_X2_table_Bayes.to_csv(algorithm+'_P_REM_given_X2-BF-fit.csv',index=False,float_format='%.'+str(precision)+'f')\n",
    "\n",
    "P_REM_given_X2_table_an_Bayes = P_REM_given_X2_table_an.iloc[:,1:]\n",
    "P_REM_given_X2_table_an_Bayes.columns = range(len(Bayes_factors))\n",
    "P_REM_given_X2_table_an_Bayes = P_REM_given_X2_table_an_Bayes.mul(Bayes_factors)\n",
    "P_REM_given_X2_table_an_Bayes.rename(columns='P_REM('+Bayes['EOS']+')',inplace=True)\n",
    "P_REM_given_X2_table_an_Bayes.insert(0,'X2',P_REM_given_X2_table_an['X2'])\n",
    "\n",
    "P_REM_given_X2_table_an_Bayes.to_csv(algorithm+'_P_REM_given_X2-BF-fit_an.csv',index=False,float_format='%.'+str(precision)+'f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
