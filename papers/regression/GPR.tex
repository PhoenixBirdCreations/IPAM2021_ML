\subsection{Gaussian Process Regression}

\lorena{Gaussian process regression is a sophisticated mathematical tool to
find joint Gaussian distributions between system data and the predictions. 
This makes it particularly powerful in interpolating between data sets and 
estimating errors. Throughout this paper, we use \texttt{PyTorch}'s GPR
module.}

\lorena{In ML algorithms one has to make certain choices to create a model. 
In the case of GPR, the kernel function, loss function, learning rate, and  
number of iterations need to be fixed. A kernel function is a covariance function 
used to measure the similarity between two data points. Our choice of kernel for 
training is the radial basis function (RBF) which is a squared exponential 
function given by}
\begin{equation}
K(X_1, X_2) = e^{-\frac{||X_1-X_2||^2}{2 \sigma^2}},
\end{equation}
\lorena{where $X_1$ and $X_2$ are input data points and $\sigma$ is the
variance, or lengthscale parameter. Apart from its popularity and versatility, 
we chose this kernel for its balance between accuracy and speed. Other kernels
tested had the advantage of faster training but with a slightly higher loss in 
accuracy. More complex, slower kernels were not considered as there was no
significant accuracy gain. We use the gradient-based Adams optimimization 
algorithm~\cite{Kingma:2014vow} with a learning rate of $0.1$ for $20$ 
iterations to find the optimal hyperparameters. The loss function we use is 
the negative marginal log-likelihood. This combination of learning rate and 
iterations allows us to decrease the loss function at a quick rate without 
sacrificing accuracy.}
