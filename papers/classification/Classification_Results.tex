\section{Results\label{results}}
In this section we show the results for our methodology. First we illustrate the good performance of our classifiers, both \ac{RF} and \ac{KNN}. Then we can use them to construct Bayesian probabilities according to their output and finally evaluate new events, synthetic and real.

\subsection{Performance of the algorithms}
We measure the performance of our algorithms by the true positive and false positive rates, drawn as \textit{Receiver Operating Characteristic} (ROC) curves. They show the variation of the true-positive rate  with the false-positive rate given a certain threshold for the probability.  The better the classifier, the steeper the curve,  achieving a greater number of true positives with few false classifications. We use the testing set that with synthetic data from LVK's O2 run. 

The curves for \ac{KNN} are in Figure \ref{fig:rocO2_KNN}. The results are consistent among all equations of state and depict a good classification, with slitghly better results in the performance of \hasrem. The curves for \ac{RF} are in Figure \ref{fig:rocO2_RF}. The results are consistent with the ones given by \ac{KNN}, showing that both classifiers perform similarly on the testing dataset.We highlight 3 concrete cases: BHF BBB2 (EOS with lowest maximum mass for the NS), MS1 PP (EOS with largest maximum mass for the NS) and SLy (the most accepted case \mmt{[?]})

\todo{UNIFY AXIS AND SIZE OF FIGURES}

\begin{figure*}[h]
\includegraphics[width=0.45\textwidth]{roc_testing_KNN_NS}
\includegraphics[width=0.45\textwidth]{roc_testing_KNN_REM}
\caption{\label{fig:rocO2_KNN}ROC curves for the testing dataset for \ac{KNN} classfier. All 23 EoS shown in grey, in color the EoSs with minimum and maximum mass, along commonly used SLy.}
\end{figure*}

\begin{figure*}[h]
\includegraphics[width=0.45\textwidth]{ROC_O2testing_NS_RF}
\includegraphics[width=0.45\textwidth]{ROC_O2testing_REM_RF}
\caption{\label{fig:rocO2_RF}ROC curves for the testing dataset for \ac{RF} classfier. All 23 EoS shown in grey, in color the EoSs with minimum and maximum mass, along commonly used SLy. \mmt{[MMT: Please unify x axis and size of the plot.]}}
\end{figure*}



\subsection{Computation of the probabilities}
\todo{write the subsection}

Once the algorithms are trained and tested,  we compute the Bayesian probabilities defined in Section \ref{sec:bayesian_probs},  in terms of the output of the algorithms (fractions of neighbors and fractions of trees, respectively).  In order to obtain the probabilities given in Equations \ref{bayes-hasns} and \ref{bayes-hasrem} one needs to apply the algorithm on known events \mmt{[MMT: applied on O2, right?]}. 

\begin{figure*}[h]
\includegraphics[width=\textwidth]{KNN_3_eos_prob_plots}
\caption{\label{fig:bayesian_prob_fits_KNN} .}
\end{figure*}

\begin{figure*}[h]
\includegraphics[width=\textwidth]{RF_3_eos_prob_plots}
\caption{\label{fig:bayesian_prob_fits_RF} .}
\end{figure*}

In Figures \ref{fig:bayesian_prob_fits_KNN} and \ref{fig:bayesian_prob_fits_RF} , we show the fits of  the results with a Gaussian Process Regression,   performed as explained in Section \ref{sec:bayesian_probs}. In this figures we show the fits for each EOS, but one can always get a single marginalized probability applying the Bayes factors.  The fitted curves are monothonic and have a sigmoid-like shape, but that depends on the choice of the EOS. We again highlight the same equations of state as in Figures \ref{fig:rocO2_KNN} and \ref{fig:rocO2_RF}.

\subsection{Performance on new events}
We use the tables constructed \todo{write}
Table probs O3 detections: Table \ref{tab:real_data_bayesian}.

We use the marginalized Bayesian probabilities obtained with both algorithms to classify the events in MDC11 \todo{explain? or was it explained before?}. We compute the ROC curves according the ground truth of the injected events. We separate the ROC curves for the different pipelines involved in the dataset. Notice that the performance for all of them is good even if the training and computing of probabilities was performed using GstLAL exclusively. Figure \ref{fig:rocMDC_KNN} depicts the curves for KNN. It performs very well for \hasns achieving a true positive rate very close to unity with a very small false positive rate. We observe that spiir pipeline deviates from the good behaviour. For \hasrem the overall performance is slightly worse, getting higher false positive rate, but in turn all pipelines behave equally good. In figure \ref{fig:rocMDC_RF} we showcase the results for \ac{RF}. As with \ac{KNN} the results are very good, with steep ROC curves. For \hasns spiir pipeline deviates less from the rest, getting higher positive rates for the same false positives than with \ac{KNN}. In the case of \hasrem the curves of the different pipelines behave a bit more differently from each other.

\begin{figure*}[h]
\includegraphics[width=0.45\textwidth]{KNN_bayesian_NS}
\includegraphics[width=0.45\textwidth]{KNN_bayesian_REM}
\caption{\label{fig:rocMDC_KNN}ROC curves of Bayesian probability marginalized for the 23 EoSs for MDC11 dataset using \ac{KNN} classifier.}
\end{figure*}

\begin{figure*}[h]
\includegraphics[width=0.45\textwidth]{RF_bayesian_NS}
\includegraphics[width=0.45\textwidth]{RF_bayesian_REM}
\caption{\label{fig:rocMDC_KNN}ROC curves of Bayesian probability marginalized for the 23 EoSs for MDC11 dataset using \ac{RF} classifier.}
\end{figure*}


Parameter sweeps:  Figures \ref{fig:param_sweep_KNN} and \ref{fig:param_sweep_RF}.

\begin{figure*}[h]
\includegraphics[width=\textwidth]{KNN_parameter_sweep}
\caption{\label{fig:param_sweep_KNN}.}
\end{figure*}

\begin{figure*}[h]
\includegraphics[width=\textwidth]{RF_parameter_sweep}
\caption{\label{fig:param_sweep_RF}.}
\end{figure*}


%Here are the results for the methods:

%\input{KNN_Results.tex} %plots and comments
%\input{RF_Results.tex} %plots and comments
%\input{GP_Results.tex}


%In order to decide which method gives a better performance in classifying this kind of events, we can apply them over testing data and finally do a comparison between both. A way to see how data is classified we can construct histograms where the number of events that are classified with a label (\texttt{HasNS/HasRemnant}) \texttt{True} or \texttt{False} will change with a given threshold of the probability. For an algorithm with perfect performance, all the events with label \texttt{True (False)} should be at \textit{p}(\texttt{label}) = 1 (\textit{p}(\texttt{label}) = 0).

%Another way to check the algorithm's performance is by building the so-called \textit{Receiver Operating Characteristic (ROC) Curve}. They show the variation of the true-positive rate (or efficiency) with the false-positive rate given a certain threshold for the probability. An algorithm with a proper performance will give a steeper ROC curve, or in other words, will have a higher eficiency with a lower false-positive rate.  


%In the ROC curves that we will present in the following subsections, we highlight three reference EoS in color, from which we show results in more detail. We select BHF\_BBB2 because is the model that give the lowest maximum mass, MS1\_PP as the model with the bigger maximum mass, and we also include SLy because is the most accepted EoS for NS modeling (reference), and is the one that was used in the injections that are our dataset.


%\subsection{Algorithm comparison}


%Here we talk about overall results and specifically from each algorithm in the
%subsections below.  \mmt{[MMT: Below I described how to check the performance of the algorithms. Maybe a table with all the scores/sensitivities/precisions from both %KNN and RF would be useful (already got it in a google doc)]}

%\mmt{To measure the performance of the classifiers we use some common statistical quantities.  The score is the number of correctly predicted events over the number %of total events (a perfect classifier has a score of 1).  It works best when there is an equal number of events for each label in the training set. It does not %consider the importance of misclassification, or that the training data can be biased towards one specific label.}

%\mmt{The mean score is computed by training the algorithm on the $90\%$ of the dataset and testing it on the remaining $10\%$, cycling the train/test combination over %the full dataset. To do that, we are going to use the training dataset, since it's the larger one.  In order to train and test the model and create the different %plots, we are going to use the training and testing files. }

%\mmt{Another useful quantity is the sensitivity. It is the ratio between the true positives and the sum of the true positives and false negatives.  It measures how %much the algorithm predicts \textit{true} (in our case it would be that the event has NS or has REM), when it is actually \textit{true}.Having a sensitivity equal to %1 would mean that our method predicts \textit{true} for every event. Therefore, a method with high sensitivity will barely miss true alarms. }

%\mmt{A quantity that measures how much you can trust a method when it predicts \textit{true} is the precision.  It is the ratio between the true positives and the %some of the true  and the false positives. A precision equal to 1 means that the method never predicts \textit{true} when it is actually \textit{false}. This means %that the method will never give false alarms. }

%\mmt{Finally, the F1 score $F1 = 2(\rm{precision \times sensitivity})/(\rm{precision+sensitivity})$ is a type of score that takes into consideration how precision and %sensitivity compensate each other. A perfect classifier would have a F1 score of 1.}

%To compare quantitatively the results from RF and KNN we compute the true positive and false positive rate for several threshold values, for both HasNS and HasREM, for the three selected EoS. These are tables \ref{tab:TPbhf}, \ref{tab:TPms1} and \ref{tab:TPsly}. For HasNS the two algorithms perform similarly, with almost the same TP for all threshold values and accross EoSs, although the false positive is smaller always in the RF. For HasREM we obtain that RF performs better than KNN in every case, with not only a smaller false positive rate, but a greater true positive rate.

%\begin{table}[]
%\centering
%\begin{tabular}{@{}c|cccc|cccc@{}}
%\toprule
%\multicolumn{1}{l|}{}          & \multicolumn{4}{c|}{Has NS}                       & \multicolumn{4}{c}{Has REM}                      \\ \midrule
%                               & \multicolumn{2}{c}{RF} & \multicolumn{2}{c|}{KNN} & \multicolumn{2}{c}{RF} & \multicolumn{2}{c}{KNN} \\
%\multicolumn{1}{l|}{Threshold} & TP         & FP        & TP          & FP         & TP         & FP        & TP         & FP         \\ \midrule
%0.1                            & 0.999      & 0.107     &   0.999          &  0.156          & 0.998      & 0.011     &    0.992        &  0.051          \\
%0.3                            & 0.998      & 0.068     &   0.996        &  0.117          & 0.993      & 0.005     &   0.974         &  0.017          \\
%0.5                            & 0.994      & 0.042     &   0.991          &  0.088           & 0.985      & 0.003     &   0.937         &  0.006          \\
%0.8                            & 0.967      & 0.014     &   0.966          & 0.043            & 0.957      & 0.001     &  0.845          &   0.001         \\ %\bottomrule
%\end{tabular}
%\caption{BHF\_BB2}
%\label{tab:TPbhf}
%\end{table}


\begin{comment}
\begin{table}[]
\begin{tabular}{c|c|ccr|ccr}
\hline
\multicolumn{1}{c|}{}         & \multicolumn{1}{l|}{} & \multicolumn{3}{c|}{p(HasNS)}                                                & \multicolumn{3}{c}{p(HasREM)}                                                \\ \hline
\multicolumn{1}{c|}{event ID} & grace\_id             & \multicolumn{1}{c}{RF} & \multicolumn{1}{c}{KNN} & \multicolumn{1}{c|}{GP} & \multicolumn{1}{c}{RF} & \multicolumn{1}{c}{KNN} & \multicolumn{1}{c|}{GP} \\ \hline
GW170823                      & G298936               & 0.000                   & 0.000                    & 0.014                   & 0.000                   & 0.000                    & 0.001                   \\
GW170817                      & G298048               & 1.000                   & 1.000                    & 0.999                   & 1.000                   & 1.000                    & 0.995                   \\
GW170814                      & G297595               & 0.000                   & 0.000                    & 0.013                   & 0.000                   & 0.000                    & 0.001                   \\
GW170809                      & G296853               & 0.002                   & 0.000                    & 0.013                   & 0.000                   & 0.000                    & 0.001                   \\
GW190408                      & G329243               & 0.000                   & 0.000                    & 0.013                   & 0.000                   & 0.000                    & 0.001                   \\
GW190412                      & G329483               & 0.000                   & 0.000                    & 0.021                   & 0.000                   & 0.000                    & 0.001                   \\
GW190413-052954               & G329577               & 0.000                   & 0.000                    & 0.013                   & 0.000                   & 0.000                    & 0.001                   \\
GW190413-134308               & G329615               & 0.000                   & 0.000                    & 0.010                   & 0.000                   & 0.000                    & 0.001                   \\
GW190421                      & G330300               & 0.000                   & 0.000                    & 0.017                   & 0.000                   & 0.000                    & 0.001                   \\
GW190425                      & G330564               & 1.000                   & 1.000                    & 0.999                   & 0.999                   & 1.000                    & 0.994                   \\
GW190426                      & G330687               & 0.996                   & 1.000                    & 0.980                   & 0.009                   & 0.000                    & 0.008                   \\
GW190503                      & G331315               & 0.000                   & 0.000                    & 0.032                   & 0.000                   & 0.000                    & 0.001                   \\
GW190512                      & G332169               & 0.000                   & 0.000                    & 0.014                   & 0.000                   & 0.000                    & 0.001                   \\
GW190513                      & G332333               & 0.000                   & 0.000                    & 0.014                   & 0.000                   & 0.000                    & 0.001                   \\
GW190517                      & G333132               & 0.000                   & 0.000                    & 0.010                   & 0.000                   & 0.000                    & 0.001                   \\
GW190519                      & G333443               & 0.000                   & 0.000                    & 0.014                   & 0.000                   & 0.000                    & 0.001                   \\
GW190521-074359               & G333664               & 0.000                   & 0.000                    & 0.013                   & 0.000                   & 0.000                    & 0.001                   \\
GW190602                      & G335015               & 0.000                   & 0.000                    & 0.061                   & 0.000                   & 0.000                    & 0.001                   \\
GW190630                      & G337426               & 0.000                   & 0.000                    & 0.014                   & 0.000                   & 0.000                    & 0.001                   \\
GW190706                      & G337919               & 0.015                   & 0.000                    & 0.019                   & 0.000                   & 0.000                    & 0.001                   \\
GW190707                      & G337978               & 0.000                   & 0.000                    & 0.096                   & 0.000                   & 0.000                    & 0.001                   \\
GW190708                      & G338125               & 0.000                   & 0.002                    & 0.070                   & 0.000                   & 0.000                    & 0.001                   \\
GW190720                      & G344653               & 0.004                   & 0.000                    & 0.024                   & 0.000                   & 0.000                    & 0.001                   \\
GW190727                      & G345173               & 0.011                   & 0.000                    & 0.013                   & 0.000                   & 0.000                    & 0.001                   \\
GW190728                      & G345315               & 0.000                   & 0.000                    & 0.013                   & 0.000                   & 0.000                    & 0.001                   \\
GW190814                      & G347305               & 0.098                   & 0.647                    & 0.878                   & 0.000                   & 0.000                    & 0.002                   \\
GW190828-063405               & G348500               & 0.002                   & 0.000                    & 0.014                   & 0.000                   & 0.000                    & 0.001                   \\
GW190828-065509               & G348519               & 0.001                   & 0.000                    & 0.019                   & 0.000                   & 0.000                    & 0.001                   \\
GW190915                      & G350491               & 0.000                   & 0.000                    & 0.009                   & 0.000                   & 0.000                    & 0.001                   \\
GW190924                      & G351423               & 0.037                   & 0.075                    & 0.100                   & 0.000                   & 0.000                    & 0.001                   \\
GW190930                      & G351993               & 0.000                   & 0.000                    & 0.079                   & 0.000                   & 0.000                    & 0.001                   \\
GW191109                      & G354231               & 0.000                   & 0.000                    & 0.036                   & 0.000                   & 0.000                    & 0.001                   \\
GW191129                      & G355916               & 0.004                   & 0.000                    & 0.024                   & 0.000                   & 0.000                    & 0.001                   \\
GW191204-171526               & G356500               & 0.000                   & 0.000                    & 0.026                   & 0.000                   & 0.000                    & 0.001                   \\
GW191215                      & G357403               & 0.000                   & 0.000                    & 0.017                   & 0.000                   & 0.000                    & 0.001                   \\
GW191216                      & G357490               & 0.000                   & 0.000                    & 0.125                   & 0.000                   & 0.000                    & 0.001                   \\
GW191222                      & G358088               & 0.000                   & 0.000                    & 0.028                   & 0.000                   & 0.000                    & 0.001                   \\
GW200112                      & G359994               & 0.000                   & 0.000                    & 0.015                   & 0.000                   & 0.000                    & 0.001                   \\
GW200115                      & G360364               & 0.997                   & 1.000                    & 0.987                   & 1.000                   & 0.000                    & 0.011                   \\
GW200129                      & G361581               & 0.000                   & 0.000                    & 0.015                   & 0.000                   & 0.000                    & 0.001                   \\
GW200219                      & G364596               & 0.000                   & 0.000                    & 0.027                   & 0.000                   & 0.000                    & 0.001                   \\
GW200224                      & G365371               & 0.014                   & 0.000                    & 0.027                   & 0.000                   & 0.000                    & 0.001                   \\
GW200225                      & G365427               & 0.001                   & 0.000                    & 0.013                   & 0.000                   & 0.000                    & 0.001                   \\
GW200302                      & G366190               & 0.000                   & 0.000                    & 0.014                   & 0.000                   & 0.000                    & 0.001                   \\
GW200311                      & G367788               & 0.000                   & 0.000                    & 0.01                    & 0.000                   & 0.000                    & 0.001                   \\
GW200316                      & G368545               & 0.000                   & 0.000                    & 0.068                   & 0.000                   & 0.000                    & 0.001                   \\
GW200322                      & G369200               & 0.012                   & 0.000                    & 0.031                   & 0.000                   & 0.000                    & 0.001                   \\ \cline{1-1} \cline{3-4} \cline{6-7}
\hline
\end{tabular}
\caption{PROBAB TABLE REAL DATA - from algo. Update to marginalized bayesian or remove.}
\label{tab:real_data}
\end{table}
\end{comment}


\begin{table}[]
\begin{tabular}{c|c|cc|cc}
\hline
\multicolumn{1}{c|}{}         & \multicolumn{1}{l|}{} & \multicolumn{2}{c|}{$P(\hasns)$}                                                & \multicolumn{2}{c}{$P(\hasrem)$}                                                \\ \hline
\multicolumn{1}{c|}{event ID} & grace\_id             & \multicolumn{1}{c}{RF} & \multicolumn{1}{c}{KNN}  & \multicolumn{1}{c}{RF} & \multicolumn{1}{c}{KNN} \\ \hline
GW170817                      & G298048               & 1.000                   & 1.000                    & 1.000                   & 1.000                                  \\
GW190425                      & G330564               & 1.000                   & 1.000                    & 0.999                   & 1.000                             \\
GW190426                      & G330687               & 0.996                   & 1.000                    & 0.009                   & 0.000                     \\
GW190814                      & G347305               & 0.098                   & 0.647                    & 0.000                   & 0.000                      \\
GW190924                      & G351423               & 0.037                   & 0.075                    & 0.000                   & 0.000                       \\               
GW200115                      & G360364               & 0.997                   & 0.987                   & 0.006                   & 0.000                           \\
\hline
\end{tabular}
\caption{Short table with probabilities (from algo) for O3 real events. I don't think we want this anymore. \mmt{[MMT: we can remove, let's see what Marco thinks.]}}
\label{tab:real_data_short}
\end{table}

\begin{table}[]
\begin{tabular}{c|c|cc|cc}
\hline
\multicolumn{1}{c|}{}         & \multicolumn{1}{l|}{} & \multicolumn{2}{c|}{$P_M(\hasns|{\bf A}_{\bf E})$}                                                & \multicolumn{2}{c}{$P_M(\hasrem|{\bf A}_{\bf E})$}                                                \\ \hline
\multicolumn{1}{c|}{event ID} & grace\_id             & \multicolumn{1}{c}{RF} & \multicolumn{1}{c}{KNN}  & \multicolumn{1}{c}{RF} & \multicolumn{1}{c}{KNN} \\ \hline
GW170817                      & G298048               & 0.9977                   & 0.9885                    & 0.9970                   & 0.9847                                  \\
GW190425                      & G330564               & 0.9977                   & 0.9885                    & 0.9969                   & 0.9847                             \\
GW190426                      & G330687               & 0.9971                   & 0.9847                    & 0.0003                   & 0.0                     \\
GW190814                      & G347305               & 0.0418                   & 0.5665                   & 0.0                  & 0.0                      \\
GW190924                      & G351423               & 0.0122                   & 0.0536                   & 0.0                   & 0.0                       \\               
GW200115                      & G360364               & 0.9976                   & 0.9885                   & 0.0                  & 0.0                           \\
\hline
\end{tabular}
\caption{Short table with BAYESIAN probabilities for O3 real events. Marginalized, right? \mmt{[MMT: Yes, marginalized.]}}
\label{tab:real_data_bayesian}
\end{table}

