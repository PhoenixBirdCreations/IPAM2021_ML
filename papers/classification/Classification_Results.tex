%\section{Results}
%Here we talk about overall results and specifically from each algorithm in the
%subsections below.  \mmt{[MMT: Below I described how to check the performance of the algorithms. Maybe a table with all the scores/sensitivities/precisions from both %KNN and RF would be useful (already got it in a google doc)]}

%\mmt{To measure the performance of the classifiers we use some common statistical quantities.  The score is the number of correctly predicted events over the number %of total events (a perfect classifier has a score of 1).  It works best when there is an equal number of events for each label in the training set. It does not %consider the importance of misclassification, or that the training data can be biased towards one specific label.}

%\mmt{The mean score is computed by training the algorithm on the $90\%$ of the dataset and testing it on the remaining $10\%$, cycling the train/test combination over %the full dataset. To do that, we are going to use the training dataset, since it's the larger one.  In order to train and test the model and create the different %plots, we are going to use the training and testing files. }

%\mmt{Another useful quantity is the sensitivity. It is the ratio between the true positives and the sum of the true positives and false negatives.  It measures how %much the algorithm predicts \textit{true} (in our case it would be that the event has NS or has REM), when it is actually \textit{true}.Having a sensitivity equal to %1 would mean that our method predicts \textit{true} for every event. Therefore, a method with high sensitivity will barely miss true alarms. }

%\mmt{A quantity that measures how much you can trust a method when it predicts \textit{true} is the precision.  It is the ratio between the true positives and the %some of the true  and the false positives. A precision equal to 1 means that the method never predicts \textit{true} when it is actually \textit{false}. This means %that the method will never give false alarms. }

%\mmt{Finally, the F1 score $F1 = 2(\rm{precision \times sensitivity})/(\rm{precision+sensitivity})$ is a type of score that takes into consideration how precision and %sensitivity compensate each other. A perfect classifier would have a F1 score of 1.}



\begin{table}[]
\centering
\begin{tabular}{@{}c|cccc|cccc@{}}
\toprule
\multicolumn{1}{l|}{}          & \multicolumn{4}{c|}{Has NS}                       & \multicolumn{4}{c}{Has REM}                      \\ \midrule
                               & \multicolumn{2}{c}{RF} & \multicolumn{2}{c|}{KNN} & \multicolumn{2}{c}{RF} & \multicolumn{2}{c}{KNN} \\
\multicolumn{1}{l|}{Threshold} & TP         & FP        & TP          & FP         & TP         & FP        & TP         & FP         \\ \midrule
0.1                            & 0.999      & 0.107     &   0.999          &  0.156          & 0.998      & 0.011     &    0.992        &  0.051          \\
0.3                            & 0.998      & 0.068     &   0.996        &  0.117          & 0.993      & 0.005     &   0.974         &  0.017          \\
0.5                            & 0.994      & 0.042     &   0.991          &  0.088           & 0.985      & 0.003     &   0.937         &  0.006          \\
0.8                            & 0.967      & 0.014     &   0.966          & 0.043            & 0.957      & 0.001     &  0.845          &   0.001         \\ \bottomrule
\end{tabular}
\caption{BHF\_BB2}
\label{tab:my-table}
\end{table}


\begin{table}[]
\centering
\begin{tabular}{@{}c|cccc|cccc@{}}
\toprule
\multicolumn{1}{l|}{}          & \multicolumn{4}{c|}{Has NS}                       & \multicolumn{4}{c}{Has REM}                      \\ \midrule
                               & \multicolumn{2}{c}{RF} & \multicolumn{2}{c|}{KNN} & \multicolumn{2}{c}{RF} & \multicolumn{2}{c}{KNN} \\
\multicolumn{1}{l|}{Threshold} & TP         & FP        & TP          & FP         & TP         & FP        & TP         & FP         \\ \midrule
0.1                            & 1.000      & 0.114     &    0.999         & 0.138           & 0.999      & 0.023     &    0.995        &  0.103         \\
0.3                            & 0.998      & 0.065     &   0.995          & 0.097            & 0.996      & 0.010     &  0.983          & 0.044           \\
0.5                            & 0.994      & 0.036     &  0.989           & 0.068           & 0.990      & 0.004     &   0.961         & 0.019           \\
0.8                            & 0.968      & 0.011     &    0.967         & 0.031            & 0.967      & 0.001     &   0.899         &   0.004         \\ \bottomrule
\end{tabular}
\caption{MS1\_PP}
\label{tab:my-table}
\end{table}

\begin{table}[]
\centering
\begin{tabular}{@{}c|cccc|cccc@{}}
\toprule
\multicolumn{1}{l|}{}          & \multicolumn{4}{c|}{Has NS}                       & \multicolumn{4}{c}{Has REM}                      \\ \midrule
                               & \multicolumn{2}{c}{RF} & \multicolumn{2}{c|}{KNN} & \multicolumn{2}{c}{RF} & \multicolumn{2}{c}{KNN} \\
\multicolumn{1}{l|}{Threshold} & TP         & FP        & TP          & FP         & TP         & FP        & TP         & FP         \\ \midrule
0.1                            & 1.000      & 0.107     &   0.999          &           0.155 & 0.998      & 0.013     &  0.992          & 0.059           \\
0.3                            & 0.999      & 0.064     &  0.996           &           0.112 & 0.993      & 0.005     & 0.974           & 0.020           \\
0.5                            & 0.994      & 0.038     &  0.990           &           0.084 & 0.986      & 0.003     & 0.940           &   0.007         \\
0.8                            & 0.965      & 0.012     &   0.965          &           0.040 & 0.958      & 0.001     & 0.848           &  0.001          \\ \bottomrule
\end{tabular}
\caption{SLy}
\label{tab:my-table}
\end{table}
