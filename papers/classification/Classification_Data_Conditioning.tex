\subsection{Data set\label{dataset}}
\label{sec:dataset}

We use a large data set $D$ of simulated \ac{BNS}, \ac{NSBH}, and \ac{BBH} events that was first used for the space-time volume sensitivity analysis of the \ac{LVK} GstLAL search
\todo{cite Messick, Tsukada, Ewing} and later employed in Ref.~\cite{Chatterjee:2019avs}. This allows us to directly compare the performance of the various algorithms and the new labeling
scheme to the performance of the \ac{KNN} algorithm that is deployed in the current \ac{LVK} observing run. 

The simulated signals are coherently injected in two-detector data from the \ac{O2} \ac{LVK} observing run. The injection population is built with uniform/loguniform \todo{What does
uniform/loguniform means? it is uniform or loguniform?} distribution of the \todo{component? total? chirp?} masses. The component spins are aligned and injected according to isotropic
distributions. Further details on the waveforms and injection parameters can be found in Ref.~\cite{Chatterjee:2019avs}. The data set $D$ includes approximately 200,000 injected signals
that are recovered by the GstLAL pipeline with a \ac{FAR} $\le$ 1/month. The \ac{RF} and \ac{KNN} algorithms are trained and tested on the injected and recovered intrinsic source
properties (primary and secondary masses and spins) and on the recovered \ac{SNR}. 

