\section{Dataset and labeling}
\label{sec:dataset}
HasNS true if m2inj<3Ms

HasREM Focault remnant mass >0. Requires compactness so it is model dependent. The O2 dataset used 2H EoS. Later we do the training with 23 EoS and do a weighted average according to the Bayes factor of each EoS, obtaining analogous performance.

Until here is same as Deep.

NEW: Instead of training two different classifiers, one for each feature, as they are in part related (an event cannot have remnant if there is no NS) we build 3 mutually exclusive categories: label 0 if no NS and no remnant, label 1 if NS but no remnant, label 2 if both. This labeling eliminates the posibility of an unphysical classification of the event, where pHasRem>pHasNS, as there is no category for hasREM but no NS. As the categories are mutually exclusive $p(0)+p(1)+p(2)=1$. Trivially p(HasREM)=p(2). And for the NS
p(hasNS)=p(hasNS and hasREM $\cup$ hasNS and No hasREM)=p(2$\cup$1)=p(2)+p(1)=1-p(0)


\begin{table}[h]
\centering
\begin{tabular}{@{}ccc@{}}
\toprule
HasNS & HasRem & Our label \\ \midrule
0     & 0      & 0         \\
1     & 0      & 1         \\
1     & 1      & 2         \\ \bottomrule
\end{tabular}
\caption{Labelling adopted for classification of having a NS and having a remnant with the same classifier}
\label{tab:labels}
\end{table}

We test the performance using random forest (RF) and compare the results with k-nearest neighbors (KNN) [paper Deep] and genetic programming (GP) [paper GP].

140k training samples. 60k for testing. Training/testing dataset: injections in O2 data stream. (Injections time and waveform approximants detailed in Chatterjee et al 2020). Labeling with the 3 categories the classes are pretty even (30.38\% for label 0, 36.30\% for label 1 and 33.32\% for label 2), which is needed for good accuracy on classification. If not, a classifier would always be biased to the category that it has seen the most. 
