\section{Introduction}
In our introduction we want to start from big picture (LIGO, ML, pipelines)
and narrow down to what work we are presenting here and why it is important. We
also describe in which ways it is novel and how it compares to previous works
like in~\cite{Chatterjee:2019avs}. We may also want to cite~\cite{Sachdev:2020lfd}. 


The breakthrough observation of the binary neutron star (BNS) merger simultaneously in gravitational and electromagnetic (E/M) waves \cite{LIGOScientific:2017ync} marked a new era of multi-messenger astronomy including for first time gravitational waves (GWs). The event GW170817 gave answers to open questions, such as the origin and production of Gamma-ray bursts (*cite), the production of heavy elements during a merger of BNS (*cite), rule out Equations of States (*cite) and alternative theories of gravity (*cite), +?. Among the challenges that it brings is the early alert of the E/M telescopes. Some of the expected sources to produce an E/M counterpart are the coalescences of a neutron star with another neutron star (NSNS) or with a black hole (NSBH). In the case of NSNS: GRBs, neutron star. For NSBH: accretion disk --> short GRBs.

Numerical relativity simulations can provide accurate information about the coalesence of the binary system and its aftermath/remnant. However, these simulations are computationally expensive and require a lot of time, making them inapropriate to alert follow-up E/M searches.
- Mention empirical fits, Foucart?

In the previous observing runs of LIGO and Virgo GW observations the methods used were:
Since the first observing run (O1) LIGO and Virgo use the GstLAL-based inspiral pipeline (GstLAL) to perform matched-filtering in low latency in order to detect GWs from CBC.


- Real time inference: What was done in O2, O3 (Deep)

- Probabilities HasNS, HasRemnant

- What we suggest, Random Forest classification (what is it, what are the advantages)

In this work, we revisit and extend the problem of classification in low-latency. First, we propose the use of a combined probability of whether there is a NS in the event and whether there is a remnant. By doing so, we exclude the unphysical situation of having a larger probability of having a remnant than having a NS (like in *ref). In addition, we perform a thorough study of different algorithms, perform several tests and account for different EoSs. We povide a direct comparison between the methods we used, as well as the ones already implemented e.g. in Deep *ref. 

The structure of the paper is as follows. In Section 2 there is a detailed description of the data used. In Section 3, the classification methods, namely Random Forest and KNN are presented. 
